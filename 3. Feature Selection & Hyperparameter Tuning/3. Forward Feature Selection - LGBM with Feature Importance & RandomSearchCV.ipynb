{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BsmtFinType2_GLQ</th>\n",
       "      <th>BsmtFinType2_LwQ</th>\n",
       "      <th>BsmtFinType2_Rec</th>\n",
       "      <th>BsmtFinType2_Unf</th>\n",
       "      <th>BsmtFinType2_Unknown</th>\n",
       "      <th>HeatingQC_Fa</th>\n",
       "      <th>HeatingQC_Gd</th>\n",
       "      <th>HeatingQC_Po</th>\n",
       "      <th>HeatingQC_TA</th>\n",
       "      <th>CentralAir_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1049.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>124900.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>124900.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  SalePrice  OverallQual  YearBuilt  YearRemodAdd  BsmtFinSF1  \\\n",
       "0     1049.0   139500.0          5.0     1984.0        1984.0       552.0   \n",
       "1     1049.0   139500.0          5.0     1984.0        1984.0       552.0   \n",
       "2     1049.0   139500.0          5.0     1984.0        1984.0       552.0   \n",
       "3     1001.0   124900.0          5.0     1930.0        2007.0       737.0   \n",
       "4     1001.0   124900.0          5.0     1930.0        2007.0       737.0   \n",
       "\n",
       "   BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  1stFlrSF  ...  BsmtFinType2_GLQ  \\\n",
       "0       393.0      104.0       1049.0    1049.0  ...                 0   \n",
       "1       393.0      104.0       1049.0    1049.0  ...                 0   \n",
       "2       393.0      104.0       1049.0    1049.0  ...                 0   \n",
       "3         0.0      100.0        837.0    1001.0  ...                 0   \n",
       "4         0.0      100.0        837.0    1001.0  ...                 0   \n",
       "\n",
       "   BsmtFinType2_LwQ  BsmtFinType2_Rec  BsmtFinType2_Unf  BsmtFinType2_Unknown  \\\n",
       "0                 0                 0                 1                     0   \n",
       "1                 0                 0                 1                     0   \n",
       "2                 0                 0                 1                     0   \n",
       "3                 0                 0                 0                     0   \n",
       "4                 0                 0                 1                     0   \n",
       "\n",
       "   HeatingQC_Fa  HeatingQC_Gd  HeatingQC_Po  HeatingQC_TA  CentralAir_Y  \n",
       "0             0             0             0             1             1  \n",
       "1             0             0             0             0             1  \n",
       "2             0             0             0             1             1  \n",
       "3             0             0             0             1             1  \n",
       "4             0             0             0             0             1  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data = pd.read_csv(\"imputed_data_handle_multicollinearity.csv\")\n",
    "imputed_data=imputed_data.drop('Unnamed: 0',axis=1)\n",
    "imputed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 6, 'min_child_samples': 8, 'n_estimators': 271, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "\n",
    "\n",
    "# Separate the independent variables (features) from the dependent variable (target)\n",
    "X = imputed_data.drop('SalePrice', axis=1)\n",
    "y = imputed_data['SalePrice']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Instantiate the LightGBM regressor\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {'max_depth': sp_randint(3, 8),\n",
    "              'num_leaves': sp_randint(10, 31),\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "              'n_estimators': sp_randint(100, 301),\n",
    "              'reg_alpha': [0.1, 0.5],\n",
    "              'reg_lambda': [0.1, 0.5],\n",
    "              'min_child_samples': sp_randint(5, 16)}\n",
    "\n",
    "# Set up KFold with shuffle=True\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=100, cv=kf, n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the LightGBM regressor with the best hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the performance of the best model using cross-validation\n",
    "train_r2_scores = cross_val_score(best_model, X_train, y_train, cv=kf)\n",
    "train_r2 = np.mean(train_r2_scores)\n",
    "\n",
    "# Evaluate the performance of the best model on the test set\n",
    "test_r2 = best_model.score(X_test, y_test)\n",
    "\n",
    "# Calculate the feature importance scores for each feature in the model\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Rank the features based on their importance scores\n",
    "indices = importances.argsort()[::-1]\n",
    "\n",
    "# Create empty lists to store results\n",
    "num_features_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Loop through the number of features and fit the model\n",
    "for num_features in tqdm(range(1, 11)):\n",
    "    selected_features = X_train.columns[indices[:num_features]]\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "    model_selected = LGBMRegressor(**random_search.best_params_)\n",
    "    model_selected.fit(X_train_selected, y_train)\n",
    "    test_r2_selected = model_selected.score(X_test_selected, y_test)\n",
    "    num_features_list.append(num_features)\n",
    "    test_r2_list.append(test_r2_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators: The number of estimators is often the most critical hyperparameter in gradient boosting algorithms. Increasing the number of estimators generally improves the model's performance, but there is a tradeoff between performance and training time.\n",
    "\n",
    "max_depth: The maximum depth of the decision tree controls the complexity of the model. A higher value may lead to overfitting, while a lower value may result in underfitting. It's generally a good practice to set this hyperparameter based on the size of the dataset and the complexity of the problem.\n",
    "\n",
    "num_leaves: The maximum number of leaves in a decision tree is another important hyperparameter that affects the model's complexity. A higher value can improve the model's performance, but it can also lead to overfitting.\n",
    "\n",
    "learning_rate: The learning rate controls the step size in gradient boosting algorithms. A lower learning rate requires more iterations to converge, but it can help the model generalize better to unseen data.\n",
    "\n",
    "min_child_samples: The minimum number of samples required in each leaf node of the decision tree can prevent overfitting by forcing the model to have a minimum number of samples in each leaf.\n",
    "\n",
    "reg_lambda and reg_alpha: The L1 and L2 regularization terms can help prevent overfitting by penalizing large weights in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   importance_rank  feature_name   test_r2\n",
      "0                1    GarageArea  0.545126\n",
      "1                2     GrLivArea  0.878894\n",
      "2                3    BsmtFinSF1  0.932085\n",
      "4                4   TotalBsmtSF  0.949142\n",
      "3                5     BsmtUnfSF  0.952895\n",
      "5                6     YearBuilt  0.972983\n",
      "7                7  YearRemodAdd  0.974005\n",
      "8                8   GarageYrBlt  0.975100\n",
      "9                9      2ndFlrSF  0.975288\n",
      "6               10      1stFlrSF  0.975858\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe to store the results\n",
    "results_df = pd.DataFrame({'importance_rank': range(1, len(selected_features)+1),\n",
    "                           'feature_name': selected_features,\n",
    "                           'test_r2': test_r2_list})\n",
    "\n",
    "# Sort the dataframe by test_r2 in ascending order\n",
    "results_df = results_df.sort_values(by='test_r2')\n",
    "results_df['importance_rank'] = range(1, len(selected_features)+1)\n",
    "\n",
    "# Print the ranked feature list\n",
    "print(results_df[['importance_rank', 'feature_name', 'test_r2']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in the current working directory\n",
    "results_df.to_csv('results_lgbm.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
