{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BsmtFinType2_GLQ</th>\n",
       "      <th>BsmtFinType2_LwQ</th>\n",
       "      <th>BsmtFinType2_Rec</th>\n",
       "      <th>BsmtFinType2_Unf</th>\n",
       "      <th>BsmtFinType2_Unknown</th>\n",
       "      <th>HeatingQC_Fa</th>\n",
       "      <th>HeatingQC_Gd</th>\n",
       "      <th>HeatingQC_Po</th>\n",
       "      <th>HeatingQC_TA</th>\n",
       "      <th>CentralAir_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1049.0</td>\n",
       "      <td>139500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>124900.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>124900.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GrLivArea  SalePrice  OverallQual  YearBuilt  YearRemodAdd  BsmtFinSF1  \\\n",
       "0     1049.0   139500.0          5.0     1984.0        1984.0       552.0   \n",
       "1     1049.0   139500.0          5.0     1984.0        1984.0       552.0   \n",
       "2     1049.0   139500.0          5.0     1984.0        1984.0       552.0   \n",
       "3     1001.0   124900.0          5.0     1930.0        2007.0       737.0   \n",
       "4     1001.0   124900.0          5.0     1930.0        2007.0       737.0   \n",
       "\n",
       "   BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  1stFlrSF  ...  BsmtFinType2_GLQ  \\\n",
       "0       393.0      104.0       1049.0    1049.0  ...                 0   \n",
       "1       393.0      104.0       1049.0    1049.0  ...                 0   \n",
       "2       393.0      104.0       1049.0    1049.0  ...                 0   \n",
       "3         0.0      100.0        837.0    1001.0  ...                 0   \n",
       "4         0.0      100.0        837.0    1001.0  ...                 0   \n",
       "\n",
       "   BsmtFinType2_LwQ  BsmtFinType2_Rec  BsmtFinType2_Unf  BsmtFinType2_Unknown  \\\n",
       "0                 0                 0                 1                     0   \n",
       "1                 0                 0                 1                     0   \n",
       "2                 0                 0                 1                     0   \n",
       "3                 0                 0                 0                     0   \n",
       "4                 0                 0                 1                     0   \n",
       "\n",
       "   HeatingQC_Fa  HeatingQC_Gd  HeatingQC_Po  HeatingQC_TA  CentralAir_Y  \n",
       "0             0             0             0             1             1  \n",
       "1             0             0             0             0             1  \n",
       "2             0             0             0             1             1  \n",
       "3             0             0             0             1             1  \n",
       "4             0             0             0             0             1  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data = pd.read_csv(\"imputed_data_handle_multicollinearity.csv\")\n",
    "imputed_data=imputed_data.drop('Unnamed: 0',axis=1)\n",
    "imputed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 0.75, 'n_estimators': 400, 'min_child_weight': 10, 'max_depth': 10, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Separate the independent variables (features) from the dependent variable (target)\n",
    "X = imputed_data.drop('SalePrice', axis=1)\n",
    "y = imputed_data['SalePrice']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Set up KFold with shuffle=True\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Instantiate the XGBRegressor\n",
    "model = XGBRegressor()\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "              'max_depth': [3, 5, 7, 10],\n",
    "              'learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "              'gamma': [0, 0.1, 0.5, 1],\n",
    "              'min_child_weight': [1, 5, 10],\n",
    "              'subsample': [0.5, 0.75, 1],\n",
    "              'colsample_bytree': [0.5, 0.75, 1]}\n",
    "\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=25, cv=kf, n_jobs=-1, error_score='raise')\n",
    "\n",
    "try:\n",
    "    # Fit the RandomizedSearchCV object to the training data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors that arise during fitting\n",
    "    print(\"Error occurred during fitting:\", e)\n",
    "    \n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Train a XGBRegressor with cross-validation to get an estimate of the model's performance\n",
    "train_r2_scores = []\n",
    "test_r2_scores = []\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    model = XGBRegressor(**random_search.best_params_)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    train_r2_scores.append(model.score(X_train_fold, y_train_fold))\n",
    "    test_r2_scores.append(model.score(X_val_fold, y_val_fold))\n",
    "train_r2 = np.mean(train_r2_scores)\n",
    "test_r2 = np.mean(test_r2_scores)\n",
    "\n",
    "# Calculate the feature importance scores for each feature in the model\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Rank the features based on their importance scores\n",
    "indices = importances.argsort()[::-1]\n",
    "\n",
    "# Define the number of features\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Create empty lists to store results\n",
    "num_features_list = []\n",
    "test_r2_list = []\n",
    "\n",
    "# Loop through the number of features and fit the model\n",
    "for i in tqdm(range(1, 11)):\n",
    "    selected_features = X_train.columns[indices[:i]]\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "    model_selected = XGBRegressor(**random_search.best_params_)\n",
    "    model_selected.fit(X_train_selected, y_train)\n",
    "    test_r2_selected = model_selected.score(X_test_selected, y_test)\n",
    "    num_features_list.append(i)\n",
    "    test_r2_list.append(test_r2_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators: the number of trees in the model. Higher values generally lead to better performance, but may also increase the risk of overfitting.\n",
    "\n",
    "max_depth: the maximum depth of each tree. Higher values may capture more complex interactions in the data, but may also increase the risk of overfitting.\n",
    "\n",
    "learning_rate: the step size shrinkage used in each boosting iteration. Lower values generally lead to better performance, but may require a larger number of iterations to converge.\n",
    "\n",
    "gamma: the minimum loss reduction required to make a split in a leaf node. Higher values may lead to simpler trees and reduce overfitting, but may also underfit the data.\n",
    "\n",
    "min_child_weight: the minimum sum of instance weight required in a child node. Higher values may lead to simpler trees and reduce overfitting, but may also underfit the data.\n",
    "\n",
    "subsample: the fraction of instances to be randomly sampled for each tree. Lower values may reduce overfitting, but may also underfit the data.\n",
    "\n",
    "colsample_bytree: the fraction of features to be randomly sampled for each tree. Lower values may reduce overfitting, but may also underfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   importance_rank  feature_name   test_r2\n",
      "0                1   OverallQual  0.692702\n",
      "1                2     YearBuilt  0.726298\n",
      "2                3    Fireplaces  0.764811\n",
      "3                4     GrLivArea  0.953822\n",
      "4                5   TotalBsmtSF  0.965374\n",
      "5                6    GarageArea  0.980969\n",
      "6                7      FullBath  0.982726\n",
      "9                8      1stFlrSF  0.982771\n",
      "8                9  YearRemodAdd  0.984739\n",
      "7               10  BsmtFullBath  0.985606\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe to store the results\n",
    "results_df = pd.DataFrame({'importance_rank': range(1, len(selected_features)+1),\n",
    "                           'feature_name': selected_features,\n",
    "                           'test_r2': test_r2_list})\n",
    "\n",
    "# Sort the dataframe by test_r2 in ascending order\n",
    "results_df = results_df.sort_values(by='test_r2')\n",
    "results_df['importance_rank'] = range(1, len(selected_features)+1)\n",
    "\n",
    "# Print the ranked feature list\n",
    "print(results_df[['importance_rank', 'feature_name', 'test_r2']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results in the current working directory\n",
    "results_df.to_csv('results_xgboost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
